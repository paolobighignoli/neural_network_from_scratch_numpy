{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # to load and manipulate data\n",
    "import numpy as np # to work with vectors and matrices\n",
    "import matplotlib.pyplot as plt # to plot the results\n",
    "import matplotlib.image as mpimg # idem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/train.csv\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.iloc[:, 0].values\n",
    "\n",
    "X = data.iloc[:, 1:].values\n",
    "\n",
    "X = X/255 # normalize the data, now they are beetwen [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.07058824, 0.11764706, 0.5372549 ,\n",
       "       0.5372549 , 0.75294118, 0.3372549 , 0.28235294, 0.00392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.05098039, 0.3372549 ,\n",
       "       0.98039216, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.85098039, 0.96470588, 0.59215686, 0.1254902 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.0627451 , 0.70196078, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.90588235, 0.21176471, 0.05882353, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.28235294, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.40784314, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.23921569, 0.74901961, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.42745098, 0.3254902 , 0.78039216,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.95294118,\n",
       "       0.33333333, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6745098 , 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.79215686, 0.57647059, 0.57647059,\n",
       "       0.17647059, 0.        , 0.04313725, 0.11372549, 0.78431373,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.67058824, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00392157, 0.68235294, 0.99607843, 0.99607843, 0.34901961,\n",
       "       0.2627451 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.50196078, 0.98823529, 0.99607843,\n",
       "       0.99607843, 0.83137255, 0.29803922, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.18431373, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.11372549, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.6       , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.31372549, 0.99607843, 0.99607843, 0.94117647,\n",
       "       0.09411765, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.09803922,\n",
       "       0.94117647, 0.99607843, 0.99607843, 0.6       , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.25098039,\n",
       "       0.99607843, 0.99607843, 0.72941176, 0.02745098, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.65098039, 0.99607843,\n",
       "       0.99607843, 0.87843137, 0.04705882, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.05490196, 0.90980392, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.11372549, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.29411765, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.06666667, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.07058824,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.11372549,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18823529,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.06666667, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00784314, 0.63921569, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.11372549, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.18823529, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.06666667, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.36862745, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.78431373, 0.04705882, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.0627451 ,\n",
       "       0.81960784, 0.99607843, 0.99607843, 0.58823529, 0.00392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05882353,\n",
       "       0.80784314, 0.99607843, 0.99607843, 0.99607843, 0.79215686,\n",
       "       0.25882353, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.08235294, 0.63137255, 0.99607843, 0.99607843,\n",
       "       0.96078431, 0.12156863, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23529412, 0.83137255,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.76078431, 0.18823529,\n",
       "       0.18823529, 0.13333333, 0.16078431, 0.18823529, 0.81960784,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.67058824, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3372549 , 0.95294118, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.91372549,\n",
       "       0.95294118, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.3372549 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.44705882, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.9372549 , 0.3372549 , 0.04313725,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.05098039,\n",
       "       0.71372549, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.99607843, 0.99607843, 0.99607843, 0.99607843, 0.95294118,\n",
       "       0.2745098 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03137255, 0.29803922,\n",
       "       0.57254902, 0.99607843, 1.        , 0.99607843, 1.        ,\n",
       "       0.57254902, 0.0745098 , 0.05882353, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 300\n",
    "g = plt.imshow(X[idx].reshape(28,28)) \n",
    "print(\"Label: \", y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train = X[:1000, :]\n",
    "\n",
    "y_train = y[:1000]\n",
    "\n",
    "# now each row is a digit, we want to have each column as a digit\n",
    "X_train = X_train.T\n",
    "\n",
    "idx = 199\n",
    "plt.imshow(X_train[:, idx].reshape(28,28))\n",
    "print(\"Label: \", y[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ok perfect!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  10\n",
      "Error:  0.9757889779434415\n",
      "Accuracy:  0.15\n",
      "----------\n",
      "Iteration:  20\n",
      "Error:  0.48182366051295367\n",
      "Accuracy:  0.208\n",
      "----------\n",
      "Iteration:  30\n",
      "Error:  0.3127206929365989\n",
      "Accuracy:  0.302\n",
      "----------\n",
      "Iteration:  40\n",
      "Error:  0.2349913303043837\n",
      "Accuracy:  0.38\n",
      "----------\n",
      "Iteration:  50\n",
      "Error:  0.19118219128785052\n",
      "Accuracy:  0.448\n",
      "----------\n",
      "Iteration:  60\n",
      "Error:  0.16291293984493438\n",
      "Accuracy:  0.514\n",
      "----------\n",
      "Iteration:  70\n",
      "Error:  0.1431151883965212\n",
      "Accuracy:  0.568\n",
      "----------\n",
      "Iteration:  80\n",
      "Error:  0.12853014978582517\n",
      "Accuracy:  0.608\n",
      "----------\n",
      "Iteration:  90\n",
      "Error:  0.11741352962441487\n",
      "Accuracy:  0.644\n",
      "----------\n",
      "Iteration:  100\n",
      "Error:  0.10872589038170186\n",
      "Accuracy:  0.676\n",
      "----------\n",
      "Iteration:  110\n",
      "Error:  0.10179985311913353\n",
      "Accuracy:  0.7\n",
      "----------\n",
      "Iteration:  120\n",
      "Error:  0.0961836847783791\n",
      "Accuracy:  0.725\n",
      "----------\n",
      "Iteration:  130\n",
      "Error:  0.09155969025353766\n",
      "Accuracy:  0.745\n",
      "----------\n",
      "Iteration:  140\n",
      "Error:  0.08769811961349666\n",
      "Accuracy:  0.764\n",
      "----------\n",
      "Iteration:  150\n",
      "Error:  0.08442944639377975\n",
      "Accuracy:  0.774\n",
      "----------\n",
      "Iteration:  160\n",
      "Error:  0.08162678571090222\n",
      "Accuracy:  0.791\n",
      "----------\n",
      "Iteration:  170\n",
      "Error:  0.07919421456132918\n",
      "Accuracy:  0.801\n",
      "----------\n",
      "Iteration:  180\n",
      "Error:  0.07705869880241917\n",
      "Accuracy:  0.804\n",
      "----------\n",
      "Iteration:  190\n",
      "Error:  0.07516433042103432\n",
      "Accuracy:  0.814\n",
      "----------\n",
      "Iteration:  200\n",
      "Error:  0.0734681125770429\n",
      "Accuracy:  0.822\n",
      "----------\n",
      "Iteration:  210\n",
      "Error:  0.07193682381802506\n",
      "Accuracy:  0.83\n",
      "----------\n",
      "Iteration:  220\n",
      "Error:  0.07054465964106668\n",
      "Accuracy:  0.837\n",
      "----------\n",
      "Iteration:  230\n",
      "Error:  0.0692714477333906\n",
      "Accuracy:  0.843\n",
      "----------\n",
      "Iteration:  240\n",
      "Error:  0.06810129361291066\n",
      "Accuracy:  0.846\n",
      "----------\n",
      "Iteration:  250\n",
      "Error:  0.06702155244106771\n",
      "Accuracy:  0.849\n",
      "----------\n",
      "Iteration:  260\n",
      "Error:  0.0660220493224428\n",
      "Accuracy:  0.851\n",
      "----------\n",
      "Iteration:  270\n",
      "Error:  0.06509448925693181\n",
      "Accuracy:  0.858\n",
      "----------\n",
      "Iteration:  280\n",
      "Error:  0.06423201176957505\n",
      "Accuracy:  0.861\n",
      "----------\n",
      "Iteration:  290\n",
      "Error:  0.06342885568308305\n",
      "Accuracy:  0.866\n",
      "----------\n",
      "Iteration:  300\n",
      "Error:  0.062680107484177\n",
      "Accuracy:  0.872\n",
      "----------\n",
      "Iteration:  310\n",
      "Error:  0.061981512896203586\n",
      "Accuracy:  0.872\n",
      "----------\n",
      "Iteration:  320\n",
      "Error:  0.0613293360417352\n",
      "Accuracy:  0.877\n",
      "----------\n",
      "Iteration:  330\n",
      "Error:  0.06072025427551516\n",
      "Accuracy:  0.881\n",
      "----------\n",
      "Iteration:  340\n",
      "Error:  0.06015127962767156\n",
      "Accuracy:  0.886\n",
      "----------\n",
      "Iteration:  350\n",
      "Error:  0.05961970000274884\n",
      "Accuracy:  0.887\n",
      "----------\n",
      "Iteration:  360\n",
      "Error:  0.05912303497495831\n",
      "Accuracy:  0.889\n",
      "----------\n",
      "Iteration:  370\n",
      "Error:  0.05865900231678537\n",
      "Accuracy:  0.895\n",
      "----------\n",
      "Iteration:  380\n",
      "Error:  0.05822549238553048\n",
      "Accuracy:  0.899\n",
      "----------\n",
      "Iteration:  390\n",
      "Error:  0.05782054824045338\n",
      "Accuracy:  0.9\n",
      "----------\n",
      "Iteration:  400\n",
      "Error:  0.05744234992688645\n",
      "Accuracy:  0.901\n",
      "----------\n",
      "Iteration:  410\n",
      "Error:  0.057089201785989245\n",
      "Accuracy:  0.901\n",
      "----------\n",
      "Iteration:  420\n",
      "Error:  0.0567595219632458\n",
      "Accuracy:  0.902\n",
      "----------\n",
      "Iteration:  430\n",
      "Error:  0.056451833521354404\n",
      "Accuracy:  0.902\n",
      "----------\n",
      "Iteration:  440\n",
      "Error:  0.05616475673391417\n",
      "Accuracy:  0.903\n",
      "----------\n",
      "Iteration:  450\n",
      "Error:  0.055897002260682255\n",
      "Accuracy:  0.905\n",
      "----------\n",
      "Iteration:  460\n",
      "Error:  0.055647364994961784\n",
      "Accuracy:  0.907\n",
      "----------\n",
      "Iteration:  470\n",
      "Error:  0.055414718437849154\n",
      "Accuracy:  0.909\n",
      "----------\n",
      "Iteration:  480\n",
      "Error:  0.0551980094993987\n",
      "Accuracy:  0.91\n",
      "----------\n",
      "Iteration:  490\n",
      "Error:  0.0549962536583571\n",
      "Accuracy:  0.911\n",
      "----------\n",
      "Iteration:  500\n",
      "Error:  0.05480853043379353\n",
      "Accuracy:  0.91\n",
      "----------\n",
      "Iteration:  510\n",
      "Error:  0.0546339791365278\n",
      "Accuracy:  0.912\n",
      "----------\n",
      "Iteration:  520\n",
      "Error:  0.054471794877837515\n",
      "Accuracy:  0.912\n",
      "----------\n",
      "Iteration:  530\n",
      "Error:  0.054321224819018736\n",
      "Accuracy:  0.913\n",
      "----------\n",
      "Iteration:  540\n",
      "Error:  0.05418156464910156\n",
      "Accuracy:  0.914\n",
      "----------\n",
      "Iteration:  550\n",
      "Error:  0.05405215528016751\n",
      "Accuracy:  0.914\n",
      "----------\n",
      "Iteration:  560\n",
      "Error:  0.053932379750842856\n",
      "Accuracy:  0.915\n",
      "----------\n",
      "Iteration:  570\n",
      "Error:  0.053821660329048775\n",
      "Accuracy:  0.917\n",
      "----------\n",
      "Iteration:  580\n",
      "Error:  0.05371945580523018\n",
      "Accuracy:  0.918\n",
      "----------\n",
      "Iteration:  590\n",
      "Error:  0.05362525896725859\n",
      "Accuracy:  0.918\n",
      "----------\n",
      "Iteration:  600\n",
      "Error:  0.05353859424810484\n",
      "Accuracy:  0.918\n",
      "----------\n",
      "Iteration:  610\n",
      "Error:  0.053459015537292376\n",
      "Accuracy:  0.919\n",
      "----------\n",
      "Iteration:  620\n",
      "Error:  0.05338610414710391\n",
      "Accuracy:  0.919\n",
      "----------\n",
      "Iteration:  630\n",
      "Error:  0.05331946692454255\n",
      "Accuracy:  0.92\n",
      "----------\n",
      "Iteration:  640\n",
      "Error:  0.053258734500151006\n",
      "Accuracy:  0.919\n",
      "----------\n",
      "Iteration:  650\n",
      "Error:  0.053203559664969625\n",
      "Accuracy:  0.919\n",
      "----------\n",
      "Iteration:  660\n",
      "Error:  0.05315361586714755\n",
      "Accuracy:  0.92\n",
      "----------\n",
      "Iteration:  670\n",
      "Error:  0.0531085958200169\n",
      "Accuracy:  0.92\n",
      "----------\n",
      "Iteration:  680\n",
      "Error:  0.053068210213771325\n",
      "Accuracy:  0.92\n",
      "----------\n",
      "Iteration:  690\n",
      "Error:  0.05303218652325747\n",
      "Accuracy:  0.92\n",
      "----------\n",
      "Iteration:  700\n",
      "Error:  0.05300026790477551\n",
      "Accuracy:  0.92\n",
      "----------\n",
      "Iteration:  710\n",
      "Error:  0.05297221217518482\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  720\n",
      "Error:  0.05294779086701738\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  730\n",
      "Error:  0.052926788353703874\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  740\n",
      "Error:  0.05290900103941615\n",
      "Accuracy:  0.921\n",
      "----------\n",
      "Iteration:  750\n",
      "Error:  0.052894236608414934\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  760\n",
      "Error:  0.052882313329163114\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  770\n",
      "Error:  0.05287305940882206\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  780\n",
      "Error:  0.052866312394084104\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  790\n",
      "Error:  0.05286191861461309\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  800\n",
      "Error:  0.05285973266566434\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  810\n",
      "Error:  0.05285961692673496\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  820\n",
      "Error:  0.05286144111335304\n",
      "Accuracy:  0.922\n",
      "----------\n",
      "Iteration:  830\n",
      "Error:  0.052865081859359335\n",
      "Accuracy:  0.924\n",
      "----------\n",
      "Iteration:  840\n",
      "Error:  0.05287042232725409\n",
      "Accuracy:  0.925\n",
      "----------\n",
      "Iteration:  850\n",
      "Error:  0.05287735184439075\n",
      "Accuracy:  0.925\n",
      "----------\n",
      "Iteration:  860\n",
      "Error:  0.05288576556298587\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  870\n",
      "Error:  0.052895564142088757\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  880\n",
      "Error:  0.05290665344981444\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  890\n",
      "Error:  0.05291894428428859\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  900\n",
      "Error:  0.052932352111887626\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  910\n",
      "Error:  0.052946796821477536\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  920\n",
      "Error:  0.052962202493467544\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  930\n",
      "Error:  0.05297849718259509\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  940\n",
      "Error:  0.05299561271345069\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  950\n",
      "Error:  0.053013484487835626\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  960\n",
      "Error:  0.053032051303122066\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  970\n",
      "Error:  0.05305125518085269\n",
      "Accuracy:  0.926\n",
      "----------\n",
      "Iteration:  980\n",
      "Error:  0.05307104120488308\n",
      "Accuracy:  0.925\n",
      "----------\n",
      "Iteration:  990\n",
      "Error:  0.053091357368424456\n",
      "Accuracy:  0.925\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# initialize random weights in [-1, 1]\n",
    "W = np.random.randn(10, X_train.shape[0])\n",
    "\n",
    "# extract first vector from X_train\n",
    "x1 = X_train[:, 0]\n",
    "\n",
    "# create 1-hot encoding from y\n",
    "Y = np.zeros((10, 1000))\n",
    "\n",
    "for i in range(1000):\n",
    "    Y[y[i], i] = 1\n",
    "\n",
    "# now Y contains as columns the 1-hot encoding of y labels\n",
    "y1 = Y[:, 0]\n",
    "\n",
    "# let's begin 1 round of backpropagation\n",
    "it = 1\n",
    "max_it = 1000\n",
    "\n",
    "alpha = 0.01\n",
    "\n",
    "y1_hat = W.dot(x1)\n",
    "\n",
    "delta = (y1_hat - y1)\n",
    "\n",
    "err = np.mean(delta**2)\n",
    "\n",
    "# print(\"y1_hat: \", y1_hat)\n",
    "# print(\"err: \", err)\n",
    "\n",
    "while it < max_it and err > 0.01:\n",
    "\n",
    "    # do 1 full round \n",
    "    for i in range(1000):\n",
    "        # extract current digit and current label\n",
    "        x1 = X_train[:, i]\n",
    "        y1 = Y[:, i]\n",
    "\n",
    "        # calculate prediction\n",
    "        y1_hat = W.dot(x1)\n",
    "\n",
    "        delta = (y1_hat - y1)\n",
    "\n",
    "        W_delta = delta.reshape((10,1)).dot(x1.reshape(1, 784))\n",
    "\n",
    "        W = W - W_delta*alpha\n",
    "\n",
    "    Y_hat = W.dot(X_train)\n",
    "\n",
    "    Delta = Y_hat - Y\n",
    "\n",
    "    err_vectors = np.mean(np.square(Delta), axis=0)\n",
    "\n",
    "    # calculate mean error\n",
    "    err = np.mean(err_vectors)\n",
    "\n",
    "    # compute accuracy\n",
    "\n",
    "    # Convert to abs values\n",
    "    Y_hat_abs = np.abs(Y_hat)\n",
    "\n",
    "    # extract max indices\n",
    "    max_indices = np.argmax(Y_hat_abs, axis=0)\n",
    "\n",
    "    Y_hat_zeros_ones = np.zeros(Y_hat_abs.shape)\n",
    "\n",
    "    for i in range(1000):\n",
    "        Y_hat_zeros_ones[max_indices[i], i] = 1.0\n",
    "\n",
    "    # Step 1: Compare each column of Y and Y_hat to check if the positions of the 1s match\n",
    "    matches = np.all(Y == Y_hat_zeros_ones, axis=0)\n",
    "\n",
    "    # Step 2: Count the number of columns where the positions match\n",
    "    correct_predictions = np.sum(matches)\n",
    "\n",
    "    # Step 3: Divide by the total number of columns to get the accuracy\n",
    "    total_predictions = Y.shape[1]\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "\n",
    "    if it % 10 == 0:\n",
    "        print(\"Iteration: \", it)\n",
    "        print(\"Error: \", err)\n",
    "        print(\"Accuracy: \", accuracy)\n",
    "        print(\"-\"*10)\n",
    "\n",
    "    it += 1\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok cool, 92.5% on the training set! Well, lets see how it works on the test set:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test accuracy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.458\n"
     ]
    }
   ],
   "source": [
    "X_test = X[1000:2000, :]\n",
    "\n",
    "y_test = y[1000:2000]\n",
    "\n",
    "# create 1-hot encoding from y\n",
    "Y_test = np.zeros((10, 1000))\n",
    "\n",
    "for i in range(1000):\n",
    "    Y_test[y_test[i], i] = 1\n",
    "\n",
    "idx = 333\n",
    "\n",
    "# now each row is a digit, we want to have each column as a digit\n",
    "X_test = X_test.T\n",
    "\n",
    "# predict\n",
    "Y_hat = W.dot(X_test)\n",
    "\n",
    "# Convert to abs values\n",
    "Y_hat_abs = np.abs(Y_hat)\n",
    "\n",
    "# extract max indices\n",
    "max_indices = np.argmax(Y_hat_abs, axis=0)\n",
    "\n",
    "Y_hat_zeros_ones = np.zeros(Y_hat_abs.shape)\n",
    "\n",
    "for i in range(1000):\n",
    "    Y_hat_zeros_ones[max_indices[i], i] = 1.0\n",
    "\n",
    "# Step 1: Compare each column of Y and Y_hat to check if the positions of the 1s match\n",
    "matches = np.all(Y_test == Y_hat_zeros_ones, axis=0)\n",
    "\n",
    "# Step 2: Count the number of columns where the positions match\n",
    "correct_predictions = np.sum(matches)\n",
    "\n",
    "# Step 3: Divide by the total number of columns to get the accuracy\n",
    "total_predictions = Y.shape[1]\n",
    "accuracy = correct_predictions / total_predictions\n",
    "\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some maths so far...\n",
    "\n",
    "\n",
    "So far $X \\in \\R^{784 \\times 1000}$ which means that we have 1000 observations $\\{ x_1, \\dots, x_{1000}\\}$, each one of length 784 representing a single digit. \n",
    "\n",
    "Then we have $Y \\in \\R^{10 \\times 1000}$ in which, for every column $\\{y_1, \\dots, y_{1000}\\}$ is a one hot encoding vector representing the label of the $i^{th}$ observation.\n",
    "\n",
    "We build a matrix of weights $W \\in \\R^{10 \\times 784}$ such that\n",
    "\n",
    "$$\n",
    "\\hat{Y} = W \\cdot X\n",
    "$$\n",
    "\n",
    "Considering a single observation $x_i$ we compute $\\hat{y}_i = W \\cdot x_i$ and the loss function that we use (right now) is the standard $MSE$: \n",
    "\n",
    "$$\n",
    "L(\\hat{y}_i, y_i) = \\frac{\\sum_{j =1}^{10} (\\hat{y}_{i,j}-y_{i,j})^2}{10}\n",
    "$$\n",
    "\n",
    "which in matrix form is \n",
    "\n",
    "$$\n",
    "L(\\hat{y}, y) = (W \\cdot x -y)^T \\cdot (W \\cdot x -y)\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "\\nabla L = \\dots = (W \\cdot x - y) \\cdot x^T\n",
    "$$\n",
    "\n",
    "so the update using gradient descent\n",
    "\n",
    "$$\n",
    "W = W - \\alpha \\cdot \\nabla L_{W} = W - \\alpha \\cdot (W \\cdot x - y) \\cdot x^T\n",
    "$$\n",
    "\n",
    "**N.B.**\n",
    "This is done for every observations $\\{x_i, y_i\\}$ and at each time the weights $W$ are updated, so one cycle of updates is as long as the training set (in our case 1000 weights updates).\n",
    "\n",
    "**N.B.B.**\n",
    "In some case you will see the following thing:\n",
    "\n",
    "$$\n",
    "1/n \\ \\Sigma W \\cdot \\mathbb{X}\n",
    "$$\n",
    "\n",
    "which is a compact version for computing the gradient over all $x_1, \\dots, x_n$ which are $\\mathbb{X} = [x_1 | \\dots | x_n ]$, i.e. doing the update over all the $x_i$:\n",
    "\n",
    "$$\n",
    "(W \\cdot x_1 - y) \\cdot x_1^T + (W \\cdot x_2 - y) \\cdot x_2^T + \\dots (W \\cdot x_n - y) \\cdot x_n^T\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's recap some dimensions\n",
    "\n",
    "* $x_i \\in \\R^{m}$ where $m \\in \\R^{784}$ is a single digit\n",
    "* $y_i \\in \\R^{k}$ where $k \\in \\R^{10}$ is a single vector of $0,1$ where $1$ is the correct label of $x_i$\n",
    "* $W \\in \\R^{k \\times m}$ such that $\\hat{y}_i = W \\cdot x_i$ is the prediction for $x_i$\n",
    "* $\\mathbb{X} = [x_1 | \\dots | x_n] \\in \\R^{m \\times n}$ is the matrix containing all of our digits $x_i$, and $n$ is the number of digits in our training dataset\n",
    "* $\\mathbb{Y} = [y_1 | \\dots | y_n] \\in \\R^{k \\times n}$ is the matrix containing all of labels $y_i$\n",
    "\n",
    "Then we have that the gradient descent compact is the following:\n",
    "\n",
    "$$\n",
    "(W \\cdot \\mathbb{X} - \\mathbb{Y}) \\in \\R^{k \\times n}\n",
    "$$\n",
    "\n",
    "where here each column is the difference between $\\hat{y}_i - y_i = \\delta_i$, and then we multiply it by $\\mathbb{X}^T \\in \\R^{n \\times m}$, ending up with:\n",
    "\n",
    "$$\n",
    "(W \\cdot \\mathbb{X} - \\mathbb{Y}) \\cdot \\mathbb{X}^T \\in \\R^{k \\times m}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.1 64-bit ('3.11.1')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "36aa87528da973003848376161a4d73716901319591f0c4bb70f237c64eec3af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
